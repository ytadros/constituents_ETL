{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9627a0a7",
   "metadata": {},
   "source": [
    "# Constituent Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc7e57",
   "metadata": {},
   "source": [
    "This app aggregates constituent data to produce one file containing data about each constituent and another containing the number of new acquisitions per calendar day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca13b034",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "- Ensure that your working directory contains the files \"cons.csv\", \"cons_email.csv\", and \"cons_email_chapter_subscription.csv\"\n",
    "- If you wish to apply filters to the data, change the appropriate setting in the Settings cell.\n",
    "- Run the Settings cell.\n",
    "- Run the Pipeline cell.\n",
    "- After execution, look for the files \"people.csv\" and \"acquisition_facts.csv\" in your working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290e7a3",
   "metadata": {},
   "source": [
    "## Settings\n",
    "- **Note on \"source_col\" setting:**   \n",
    "There are two fields in the constituents table which might qualify for the \"code\" column: \"source\" and \"subsource\", necessitating this setting.   \n",
    "The default setting (\"both\") means that in cases where both source and subsource are available, the \"code\" column will contain source and subsource, separated by a hyphen(-).\n",
    "Replacing \"both\" with \"source\" or \"subsource\" will pull data only from that column, ignoring the other.  \n",
    "\n",
    "\n",
    "- The other settings are filters--refer to the comments above each setting to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "5cd865e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE_COL\n",
    "# Column from which to pull source code information. Options are \"source\", \"subsource\", or \"both\"\n",
    "source_col = \"both\"\n",
    "\n",
    "# FILTER UNVALIDATED CONSTITUENTS\n",
    "# If True, only include people who are validated\n",
    "filter_unvalidated = False\n",
    "\n",
    "# FILTER BANNED CONSTITUENTS\n",
    "# If True, only include people who are not banned\n",
    "filter_banned = False\n",
    "\n",
    "# FILTER CONSTITUENT STATUS\n",
    "# If True, only include people whose status is 1 (do not include people with status == 0)\n",
    "filter_cons_status = False\n",
    "\n",
    "# FILTER CONSTITUENTS WITH NO EMAIL\n",
    "# If True, only include people who are connected with an email\n",
    "filter_no_email = False\n",
    "\n",
    "# FILTER EMAIL STATUS\n",
    "# If True, only include people whose primary email address has a status of 1 (as opposed to 0)\n",
    "filter_email_status = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8651876",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "- Please do not make any changes to this cell.\n",
    "- Please allow a few minutes for execution.  \n",
    "- After execution, \"people.csv\" and \"acquisition_facts.csv\" should appear in your working directory\n",
    "- Note: This might produce a \"FutureWarning: elementwise comparison failed\";  \n",
    "This is because of a numpy bug, and should not affect the end result: click [here](https://stackoverflow.com/questions/40659212/futurewarning-elementwise-comparison-failed-returning-scalar-but-in-the-futur) to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "72ccd628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CISS\\anaconda3\\envs\\bee2a_khayaleya\\lib\\site-packages\\numpy\\lib\\arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_source_code(row: pd.Series):\n",
    "    sources = []\n",
    "    \n",
    "    if pd.notnull(row.loc['source']) and source_col in ['both', 'source']:\n",
    "        sources.append(row.loc['source'])\n",
    "    \n",
    "    if pd.notnull(row.loc['subsource']) and source_col in ['both', 'subsource']:\n",
    "        sources.append(row.loc['subsource'])\n",
    "        \n",
    "    if sources:\n",
    "        return '-'.join(sources)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "# Extract Constituents\n",
    "constituents = pd.read_csv('cons.csv', index_col = 'cons_id', usecols=['cons_id', 'source', 'subsource', 'is_validated',\n",
    "                                                                       'is_banned', 'create_dt', 'modified_dt', 'status'])\n",
    "# Filter out unvalidated constituents\n",
    "if filter_unvalidated:\n",
    "    constituents = constituents[constituents.is_validated == 1]\n",
    "\n",
    "# Filter out banned constituents\n",
    "if filter_banned:\n",
    "    constituents = constituents[constituents.is_banned == 0]\n",
    "    \n",
    "# Filter out constituents with a status of 0\n",
    "if filter_cons_status:\n",
    "    constituents = constituents[constituents.status == 1]\n",
    "    \n",
    "constituents.drop(columns = ['is_validated', 'is_banned', 'status'], inplace=True)\n",
    "\n",
    "\n",
    "# Extract Emails\n",
    "emails = pd.read_csv('cons_email.csv', index_col='cons_email_id', usecols=['cons_email_id', 'cons_id', 'is_primary',\n",
    "                                                                           'email', 'status'])\n",
    "# Only keep primary emails\n",
    "emails = emails[emails.is_primary == 1]\n",
    "\n",
    "# Filter emails with a status of 0\n",
    "if filter_email_status:\n",
    "    emails = emails[emails.status == 1]\n",
    "\n",
    "emails.drop(columns=['is_primary', 'status'], inplace=True)\n",
    "\n",
    "\n",
    "# Extract Subscriptions\n",
    "subscriptions = pd.read_csv('cons_email_chapter_subscription.csv', index_col = 'cons_email_chapter_subscription_id')\n",
    "# Only keep chapter 1 subscriptions\n",
    "subscriptions = subscriptions[subscriptions.chapter_id == 1]\n",
    "subscriptions.drop(columns=['unsub_dt', 'modified_dt', 'chapter_id'], inplace=True)\n",
    "\n",
    "\n",
    "# Merge DataFrames\n",
    "email_sub = emails.merge(subscriptions, on='cons_email_id', how='left').set_index('cons_email_id')\n",
    "email_sub['isunsub'].fillna(0, inplace=True)\n",
    "\n",
    "# Filter constituents with no email\n",
    "merge_method = 'inner' if filter_no_email else 'left'\n",
    "\n",
    "people = constituents.merge(email_sub, on='cons_id', how=merge_method).set_index('cons_id')\n",
    "\n",
    "# Construct appropriate \"code\" column\n",
    "people['code'] = people.apply(get_source_code, axis=1)\n",
    "\n",
    "# Re-order and rename columns as per client specifications\n",
    "people = people[['email', 'code', 'isunsub', 'create_dt', 'modified_dt']]\n",
    "people.rename(columns={'isunsub': 'is_unsub', 'create_dt': 'created_dt', 'modified_dt': 'updated_dt'}, inplace=True)\n",
    "\n",
    "# Load constituent data into \"people.csv\"\n",
    "people.to_csv('people.csv')\n",
    "\n",
    "# Calculate number of acquisitions per calendar day\n",
    "dates = pd.to_datetime(people.created_dt).dt.date\n",
    "acquisition_facts = dates.value_counts().rename_axis('acquisition_date').reset_index(name='acquisitions')\n",
    "acquisition_facts.sort_values('acquisition_date', inplace=True)\n",
    "\n",
    "# Load acquisition frequency data into \"acquisition_facts.csv\"\n",
    "acquisition_facts.to_csv('acquisition_facts.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bee2a_khayaleya",
   "language": "python",
   "name": "bee2a_khayaleya"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
